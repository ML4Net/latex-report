% 03-data-exploration-and-pre-processing.tex

% Data Exploration and Pre-processing
% 3.1. Introduction: Introduces the data exploration and pre-processing tasks.
% 3.2. Dataset Preparation: Describes the process of loading the dataset and initial inspection.
% 3.3. Temporal Analysis: Analyzes when the attacks were performed.
% 3.4. Feature Extraction: Extracts features from the attack sessions.
% 3.5. Common Words Analysis: Identifies the most common words in the sessions.
% 3.6. Intent Distribution: Analyzes the distribution of intents over time.
% 3.7. Text Representation: Converts text into numerical representations (BoW, TF-IDF).

% Section Title
\section{DATA EXPLORATION AND PRE-PROCESSING}

    % Main Content

    % Subsections
    \subsection{Introduction}

        This section details the data exploration and pre-processing steps undertaken to analyze SSH shell attack logs. The tasks include dataset preparation, temporal analysis, feature extraction, common words analysis, intent distribution, and text representation.

    \subsection{Dataset Preparation}
    
        The dataset used in this research is loaded from a Parquet file (\texttt{ssh\_attacks.parquet}) into a Pandas DataFrame. The initial inspection involves checking the dataset's structure, identifying missing values, and detecting duplicate rows. The dataset contains columns such as \texttt{Session ID}, \texttt{Full session text}, \texttt{Timestamp}, and \texttt{Intent labels}.

        \begin{verbatim}
            # Load the dataset
            SSH_Attacks = pd.read_parquet("../data/processed/ssh_attacks_decoded.parquet")
    
            # Inspect the dataset structure
            print(SSH_Attacks.info())
    
            # Check for missing values
            print(SSH_Attacks.isnull().sum())
    
            # Check for duplicate rows
            print(SSH_Attacks.duplicated().sum())
        \end{verbatim}

    \subsection{Temporal Analysis}
    
        The temporal analysis examines when the attacks were performed. The \texttt{first\_timestamp} column is converted to a datetime format to analyze attack frequencies over time, including hourly, daily, and monthly trends.

        \begin{verbatim}
            # Convert first_timestamp to datetime format
            SSH_Attacks['first_timestamp'] = pd.to_datetime(SSH_Attacks['first_timestamp'])

            # Analyze attack frequencies over time
            temporal_series = (
                SSH_Attacks.groupby(SSH_Attacks['first_timestamp'].dt.date)
                .size()
                .reset_index(name='attack_count')
            )
        \end{verbatim}

        The analysis includes plotting the number of attacks per hour, month, and year to identify patterns and trends.

    \subsection{Feature Extraction}
    
        Feature extraction involves identifying and extracting relevant features from the attack sessions. This includes analyzing the distribution of classes (intents) and visualizing the data using bar plots.

        \begin{verbatim}
            # Extract and count occurrences of each class
            all_classes = SSH_Attacks['Set_Fingerprint'].explode().str.strip()
            class_counts = all_classes.value_counts()

            # Plot the distribution of classes
            sns.barplot(x=class_counts.index, y=class_counts.values, palette='viridis')
        \end{verbatim}

    \subsection{Common Words Analysis}
    
        The common words analysis identifies the most frequent words used in the attack sessions. This is achieved using word clouds and other text analysis techniques.

        \begin{verbatim}
            # Generate a word cloud for the session text
            wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(SSH_Attacks['Full session text']))
            plt.imshow(wordcloud, interpolation='bilinear')
            plt.axis('off')
            plt.show()
        \end{verbatim}

    \subsection{Intent Distribution}
            
        The intent distribution analysis examines the distribution of intents over time. This involves grouping the data by date and intent to count occurrences and visualize the trends.

        \begin{verbatim}
            # Group by Set_Fingerprint and date to count occurrences
            grouped_SSH_Attacks = (
                SSH_Attacks.explode('Set_Fingerprint')
                .groupby([SSH_Attacks['first_timestamp'].dt.date, 'Set_Fingerprint'])
                .size()
                .reset_index(name='attack_count')
            )
        \end{verbatim}

    \subsection{Text Representation}
    
        Text representation converts the session text into numerical representations using techniques such as Bag of Words (BoW) and TF-IDF. These representations are used for further analysis and machine learning tasks.

        \begin{verbatim}
            # Convert text into numerical representations
            vectorizer = TfidfVectorizer()
            X_tfidf = vectorizer.fit_transform(SSH_Attacks['Full session text'])
        \end{verbatim}

        The resulting numerical representations are normalized and used for subsequent analysis and modeling.
